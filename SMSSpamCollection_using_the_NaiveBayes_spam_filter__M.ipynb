{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBaeO7yHOMkU"
      },
      "source": [
        "<center>\n",
        " <img src = \"JHU.png\"  width=\"200\" alt=\"Johns Hopkins University logo\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULpWGwx_bfDP"
      },
      "source": [
        "# Hands-on Lab: SMS Spam Collection using the Naïve Bayes spam filter\n",
        "\n",
        "Estimated Time: **40** Minutes\n",
        "\n",
        "### Overview:\n",
        "\n",
        "In this lab, you'll develop a spam filter tool that processes email or SMS text bodies from a text file to determine whether it's spam or ham using Naïve Bayes Algorithm.\n",
        "\n",
        "### Learning Objectives:\n",
        "\n",
        "- Learn how the Naïve Bayes algorithm works and why it’s effective for text classification tasks like spam filtering.\n",
        "- Gain hands-on experience in preprocessing text data, including tokenization, stop-word removal, and feature extraction, to prepare it for machine learning models.\n",
        "- Learn how to assess the accuracy and effectiveness of your spam filter by testing it with unseen data and analyzing its performance metrics.\n",
        "- Finally, develop a spam filter using Python, leveraging the Naïve Bayes algorithm to classify emails or SMS messages as spam or ham.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6gS2fbBebE4"
      },
      "source": [
        "## Design Features\n",
        "\n",
        "To accomplish this, utilize the dataset I provided along with the ML analytic development process to create a spam filter that dynamically identifies its own suspect keywords. After developing the model, export it and write code to use the exported model for performing the spam filtering as described.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KikH2cFOOKFJ"
      },
      "source": [
        "## Problem Statement:\n",
        "\n",
        "Design and implement a spam filter tool inspired by the Naïve Bayes spam filter. The tool should take an email or SMS text body as input in the form of a text file and classify it as either spam or ham. The model should dynamically recognize suspect keywords using a provided dataset and follow the machine learning analytic development process.\n",
        "\n",
        "### Requirements\n",
        "- Python 3.x\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGeaYu4TiBc2"
      },
      "source": [
        "### Step 1: Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rmf-hERqM4zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd280fb-c382-4495-b708-cd6e95633f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Label                                            Message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('SMSSpamCollection.csv')  # Replace with your dataset path\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7IY9KTiTvY"
      },
      "source": [
        "### Step 2: Preprocess The Data\n",
        "\n",
        "- The labels (\"spam\" or \"ham\") are converted into binary values (1 for spam, 0 for ham).\n",
        "- The text data is extracted and prepared for vectorization.\n",
        "- Text Cleaning\n",
        "- Feature Extraction\n",
        "- TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "#### Explanation\n",
        "\n",
        "**Text Cleaning:**\n",
        "\n",
        "- The preprocess_text function cleans each message by converting it to lowercase, removing non-alphabetic characters, tokenizing it, and removing stop words. The cleaned text is stored in the cleaned_message column.\n",
        "\n",
        "**Feature Extraction:**\n",
        "- Bag of Words (BoW): The CountVectorizer converts the cleaned messages into a matrix of token counts.\n",
        "- TF-IDF: The TfidfVectorizer transforms the cleaned messages into a TF-IDF matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r1ibbMvCRCPx"
      },
      "outputs": [],
      "source": [
        "# Write your code here!\n",
        "# Step 1:\n",
        "# Convert the labels into binary values (1 for spam, 0 for ham)\n",
        "data['Label'] = data['Label'].map({'spam': 1, 'ham': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQbtuV4DicYd"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "data['Label'] = data['Label'].map({'spam': 1, 'ham': 0})\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rFyS9JtPbLeL"
      },
      "outputs": [],
      "source": [
        "# Step 2: Text Cleaning:\n",
        "# Import required packages\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/github/gal-a/blog/blob/master/docs/notebooks/nlp/nltk_preprocess.ipynb\n",
        "\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2iqB7JQd49O",
        "outputId": "4796e884-88d0-4a00-f5d6-48c0476bb97b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRsPwg7rbLeL",
        "outputId": "a6a0b06c-6d7c-4196-a1a1-7c8dd73e8041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Message  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                     cleaned_message  \n",
            "0  go jurong point crazy available bugis n great ...  \n",
            "1                            ok lar joking wif u oni  \n",
            "2  free entry wkly comp win fa cup final tkts st ...  \n",
            "3                u dun say early hor u c already say  \n",
            "4        nah dont think goes usf lives around though  \n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "# Step 3:\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation, special characters, and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenize the text (split into words)\n",
        "    tokens = text.split()\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Join the tokens back into a single string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the 'message' column\n",
        "data['cleaned_message'] = data['Message'].apply(preprocess_text)\n",
        "\n",
        "# Display the first few rows of the cleaned data\n",
        "print(data[['Message', 'cleaned_message']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo2FRmuBbLeL"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation, special characters, and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenize the text (split into words)\n",
        "    tokens = text.split()\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Join the tokens back into a single string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the 'message' column\n",
        "data['cleaned_message'] = data['Message'].apply(preprocess_text)\n",
        "\n",
        "# Display the first few rows of the cleaned data\n",
        "print(data[['Message', 'cleaned_message']].head())\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AlD-SqwUN0Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fded5d-24d0-4936-9f88-8bff8f22d005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (BoW):\n",
            "   aa  aah  aaniye  aaooooright  aathilove  aathiwhere  ab  abbey  abdomen  \\\n",
            "0   0    0       0            0          0           0   0      0        0   \n",
            "1   0    0       0            0          0           0   0      0        0   \n",
            "2   0    0       0            0          0           0   0      0        0   \n",
            "3   0    0       0            0          0           0   0      0        0   \n",
            "4   0    0       0            0          0           0   0      0        0   \n",
            "\n",
            "   abeg  ...  zeros  zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zs  zyada  \n",
            "0     0  ...      0   0      0       0    0          0     0     0   0      0  \n",
            "1     0  ...      0   0      0       0    0          0     0     0   0      0  \n",
            "2     0  ...      0   0      0       0    0          0     0     0   0      0  \n",
            "3     0  ...      0   0      0       0    0          0     0     0   0      0  \n",
            "4     0  ...      0   0      0       0    0          0     0     0   0      0  \n",
            "\n",
            "[5 rows x 8480 columns]\n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "# Step 4: Feature Extraction\n",
        "# Part 1 :Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Transform the cleaned text data into a matrix of token counts\n",
        "X_bow = vectorizer.fit_transform(data['cleaned_message'])\n",
        "\n",
        "# Convert the BoW matrix to a DataFrame for better readability (optional)\n",
        "bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the BoW DataFrame\n",
        "print(\"Bag of Words (BoW):\")\n",
        "print(bow_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvoqdCZivxB"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "vectorizer = CountVectorizer()\n",
        "# Transform the cleaned text data into a matrix of token counts\n",
        "X_bow = vectorizer.fit_transform(data['cleaned_message'])\n",
        "\n",
        "# Convert the BoW matrix to a DataFrame for better readability (optional)\n",
        "bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the BoW DataFrame\n",
        "print(\"Bag of Words (BoW):\")\n",
        "print(bow_df.head())\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAdfOHCabLeM",
        "outputId": "1853ec54-e272-4f4a-8b23-b1b751580531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF:\n",
            "    aa  aah  aaniye  aaooooright  aathilove  aathiwhere   ab  abbey  abdomen  \\\n",
            "0  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0      0.0   \n",
            "1  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0      0.0   \n",
            "2  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0      0.0   \n",
            "3  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0      0.0   \n",
            "4  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0      0.0   \n",
            "\n",
            "   abeg  ...  zeros   zf  zhong  zindgi  zoe  zogtorius  zoom  zouk   zs  \\\n",
            "0   0.0  ...    0.0  0.0    0.0     0.0  0.0        0.0   0.0   0.0  0.0   \n",
            "1   0.0  ...    0.0  0.0    0.0     0.0  0.0        0.0   0.0   0.0  0.0   \n",
            "2   0.0  ...    0.0  0.0    0.0     0.0  0.0        0.0   0.0   0.0  0.0   \n",
            "3   0.0  ...    0.0  0.0    0.0     0.0  0.0        0.0   0.0   0.0  0.0   \n",
            "4   0.0  ...    0.0  0.0    0.0     0.0  0.0        0.0   0.0   0.0  0.0   \n",
            "\n",
            "   zyada  \n",
            "0    0.0  \n",
            "1    0.0  \n",
            "2    0.0  \n",
            "3    0.0  \n",
            "4    0.0  \n",
            "\n",
            "[5 rows x 8480 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Feature Extraction\n",
        "# Part 2: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the cleaned text data into a TF-IDF matrix\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(data['cleaned_message'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame for better readability (optional)\n",
        "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the TF-IDF DataFrame\n",
        "print(\"\\nTF-IDF:\")\n",
        "print(tfidf_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C_a5n7ybLeM"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "# Transform the cleaned text data into a TF-IDF matrix\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(data['cleaned_message'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame for better readability (optional)\n",
        "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the TF-IDF DataFrame\n",
        "print(\"\\nTF-IDF:\")\n",
        "print(tfidf_df.head())\n",
        "    \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOhIpQi6jXAi"
      },
      "source": [
        "### Step 3: Train Naive Bayes Model\n",
        "\n",
        "- The data is split into training and testing sets.\n",
        "- A MultinomialNB Naive Bayes classifier is trained on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d5SoEdcfN1YB"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import required packages.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0HeP65DbLeN",
        "outputId": "3daa3f53-772d-4726-b484-275ceb44b4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 4459 samples\n",
            "Testing set size: 1115 samples\n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "# Define the feature matrix and target vector\n",
        "X = data['cleaned_message']  # Feature matrix (cleaned messages)\n",
        "y = data['Label']  # Target vector (labels: 'spam' or 'ham')\n",
        "\n",
        "# For Bag of Words:\n",
        "X_features = vectorizer.fit_transform(X)\n",
        "\n",
        "# For TF-IDF (uncomment the following line if you prefer TF-IDF):\n",
        "# X_features = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the size of each set\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3-4WkH2jhHa"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "# For Bag of Words:\n",
        "X_features = vectorizer.fit_transform(X)\n",
        "\n",
        "# For TF-IDF (uncomment the following line if you prefer TF-IDF):\n",
        "# X_features = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the size of each set\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "w9WupLGqbLeN",
        "outputId": "af24a70e-2818-4467-dbc2-8a343b40f8ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Write your code here!\n",
        "# Step 2: Train the model\n",
        "# Initialize the Multinomial Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRb95inMbLeN"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSGjWSFxjesK"
      },
      "source": [
        "### Step 4: Evaluate The Model\n",
        "- The model is tested on the testing set, and metrics like accuracy, precision, recall, and F1-score are printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3qu-GoLbN5yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cc104f-bcaa-401f-e4a7-6433d729d0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels:\n",
            "[0 0 0 ... 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "# Evaluate the model\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Display the predicted labels\n",
        "print(\"Predicted labels:\")\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrwgbFsjyW-"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "# Predict the labels for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Display the predicted labels\n",
        "print(\"Predicted labels:\")\n",
        "print(y_pred)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_4jq232bLeO",
        "outputId": "8c3beb52-1f9e-464b-9c07-11aa3468d29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Confusion Matrix:\n",
            "[[927  27]\n",
            " [ 10 151]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98       954\n",
            "        spam       0.85      0.94      0.89       161\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.92      0.95      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and print the classification report\n",
        "class_report = classification_report(y_test, y_pred, target_names=['ham', 'spam'])\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8PhFNwNbLeO"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and print the classification report\n",
        "class_report = classification_report(y_test, y_pred, target_names=['ham', 'spam'])\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "    \n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv7jRVpVkdwW"
      },
      "source": [
        "### Step 5: Verify The Model\n",
        "- A function classify_message() is provided to classify new SMS messages as \"spam\" or \"ham.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w6y-POnSQEsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb53e53-3c7f-42df-9633-f292f46be44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\n",
            "Classification: Spam\n"
          ]
        }
      ],
      "source": [
        "# Write your code here!\n",
        "def classify_message(message):\n",
        "    vec_message = vectorizer.transform([message])\n",
        "    prediction = model.predict(vec_message)\n",
        "    return \"Spam\" if prediction == 1 else \"Ham\"\n",
        "\n",
        "# Example usage\n",
        "new_message = \"Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\"\n",
        "print(f\"Message: {new_message}\\nClassification: {classify_message(new_message)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLC_Wk6-k2MX"
      },
      "source": [
        "<details>\n",
        "<summary>Click here to view/hide solution</summary>\n",
        "    \n",
        "```\n",
        "def classify_message(message):\n",
        "    vec_message = vectorizer.transform([message])\n",
        "    prediction = model.predict(vec_message)\n",
        "    return \"Spam\" if prediction == 1 else \"Ham\"\n",
        "\n",
        "# Example usage\n",
        "new_message = \"Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\"\n",
        "print(f\"Message: {new_message}\\nClassification: {classify_message(new_message)}\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohk-AtCMbLeP"
      },
      "source": [
        "### Summary:\n",
        "\n",
        "A spam filter tool was developed using a Naïve Bayes model to classify email or SMS text as either spam or ham. The tool takes a message as input, transforms it using a vectorizer, and predicts its classification based on the trained model. In the example code provided, a sample message about a ringtone subscription is classified as either spam or ham. The tool dynamically identifies suspicious keywords and leverages a trained model to make predictions, offering a user-friendly interface to detect spam.\n",
        "\n",
        "In addition to individual message classification, the tool can be used to verify and classify multiple messages by utilizing statements from a provided CSV file. Each message in the CSV is processed, transformed, and classified as either spam or ham using the trained Naïve Bayes model. This allows for batch processing of messages, making the tool efficient for analyzing large datasets while dynamically identifying key patterns indicative of spam."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}